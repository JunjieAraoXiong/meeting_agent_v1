汤欣钰 00:00
猫戴在身上，然后又有定位，又有糖包与翻译。嗯，去年好像就有这个，好像就有一个，去年好像有一个类似的，就是也戴在什么身上啊？狗啊？对啊，那个网站的哪里啊？那个有没有总的那个 list？如果单独发一个，OK，我来发一个这种的 list，先，这个先到，我发也行，张老师不用发。

汤欣钰 00:56
然后，嗯，要不然我们先说，嗯，就明天，不是还是下午有那个周会嘛？嗯，对，就大家最近有没有什么困难？然后以及有没有识别到什么机会、想法的？然后其他的就是例行的，比如在会上就例行同步了。主要是我觉得大会前没有什么要决策的。对，一个是那个我知道的，一个是志旭那边，对吧？他手机测这个开发的资源，或者说这种能力我们还比较短缺一些，是吧？行，这个是已经知道了。

汤欣钰 01:36
对，我看这个黑马项目他们都有在全捷 OA 上部署一些 1.5B 的端观测模型。嗯，完全是比我们这个参数量要大得多，然后好像还行，那可以联系下他们，是吧？反正就是那个黑马，这个马拉松上，对，我觉得可能那些人也很重要，看哪些人有意思，然后跟他们聊一聊。

汤欣钰 02:04
你这个知道，然后我再问一下这边的 Buzz，是吧？然后我也留了。那个还有没有什么困难啊？有没有大家觉得遇到一些困难的？对。嗯，有个比较大的困难，就跟上头聊的那个隐私模式，其实感觉没有特别好的思路。嗯，但是我又回归到那个眼镜问题，因为之前谷歌他们不是也遇到很难解释的问题嘛？嗯，然后回顾了一下雷朋的解法，那个 Meta 的解法，但是到咱们这块，语音相关的那个人还没有特别好的一个。行，这个待会我们再说。行，这个同学大概知道了。

汤欣钰 02:55
我拿得到的哦。我已经在录了，我也把它操，我看我把这个分享到群里。

汤欣钰 03:25
你，所以你觉得你自己最，不是，你的目标，你想解决的是那个什么？你达到什么样的预期？今年达到一个预期，就是我可以再具体一点的，在那里面就是，其实录音笔这个形态本身很难让这个人放松那个戒备。就哪怕我跟他，嗯，开始跟我讲了，我现在只做那个信息的收集，不做原始近期的处理，我只做一些简要或者摘要，但是很难让别人信任。之后你都自由，不让你的，你就没有意愿。

汤欣钰 04:00
其实这个是一个很难看的一个团队的点，然后其实就是一个用户认知的问题。对，你们这样的话，就是对我们产品的，就是，嗯，经常携带，好像。但这个就是说，如果比如告诉他我们这个产品，大家都知道这类产品是什么都不亮的，但假如我们其他不亮的，嗯，对，就这种产品我们首先要是，当然是经得住考验的，就是他是会有原始录音的。就是还是看有没有这一条的话。没有原始录音这一条的话，是否能让用户接受？原来有些人是不接受的，但是这个接受度的范围开始能乘以 10，乘以 100，对吧？就是有 100 倍的人因为这一点他就接受了。明白意思，对，所以就看这一点。就是那天那个曲爷，是吧？他自己都用这个带录音的，他录的地方其实都有，也有压力，对吧？如果要听地方，反正。但他一听这个故事，一回搭起来，就从不接受变成接受，对吧？那就类似这样的转变，能有多少人？我觉得这是产品。他可能不是指 100%，但是能乘一个 10，对吧？这也可能会用起来，你懂我意思，所以我觉得产品这次先不用去特别想。

汤欣钰 05:26
其实我还整理了一个文档，我发群里，就是那个谷歌，他们当时就是因为这个早期。是啊，但是我看微信就是说，对，这个事情其实这么多年下来其实已经有转变了。对啊，因为现在拍这种短视频的，对吧？到处路上拍 vlog 的。嗯，其实很多没有，也没有说你不能把我删掉，对吧？对吧？好像这个东西其实也在转变，所以我觉得这种习惯对我们的认知也会在发生变化。就没有十年前那么严格。对，但是我最近串起来一个点，就是雷朋刚开始的那个 Meta，刚开始跟雷朋合作的时候可能还没那么清晰。然后现在他又跟运动，也是叫 Oakley 还是 Oakland？《候选：奥克利｜奥克兰》，那个品牌的。

汤欣钰 06:08
所以大体来讲，他跟墨镜合作的话，大概的场景就是沙滩跟运动。他跟运动眼镜合作的话，就是那些基金人在那些场景下的被拍摄或者拍摄需求。但是我理解他们的场景应该是他们的新趋势，有没有注意力？那在于说我在其他地方不用验证，对吧？我在签运动也好，但是商家能够效果，对吧？那我也会带个路径。

汤欣钰 06:37
嗯，所以我觉得那个场景倒不是说谁被拍的问题，对吧？就戴的人戴不戴？对，你看我这个时候我就不会戴一个眼镜，就不然你就发现只有我一个人戴眼镜。嗯，哈哈，对，我觉得就是他还是有那个使用的一些天生场景。运动的话，我觉得他就会有一定记录的需求。

汤欣钰 06:59
我先不管对方愿不愿意，就拍这个，对吧？我开个会，我戴个眼镜，其实你说我能得到多少信息啊？对，我现在比如说我先戴个眼镜，我录，对吧？没有意义。而且这种的，比如一些小米眼镜，那个录的时间很短，一天也就 30 分钟，对吧？我不知道剩下的 30 分钟用在哪里，大概不会用在开会里。我觉得开会里面有些视频，这个图像、画面并不是关键信息量。有在沙滩上旅游、极限运动，他可能就是短暂的 30 分钟，甚至跳下去 5 分钟，是吧？那说不定就有些用。

汤欣钰 07:37
对，我觉得这个是。所以我觉得那个眼镜核心问题还是有点层不够刚需啊。因为他只能搜一些相对来说必要的一些场景，可能是这样可以的。要不然我也不会等着我在开会的时候再戴个墨镜，对吧？这个小米就很诡异，你不觉得吗？嗯，所以我觉得那些场景的话可能需求量会更加刚一点，更加真实一些。

汤欣钰 08:05
好吧，我当然记得这样。所以我自己上周是觉得我自己的最新观点，就是我觉得研究这个东西，那个 Dignote 的创始人也好，还是对，本人肯定是 CEO，他觉得眼镜这个东西有点有需求，有点非常需。对，我之前就觉得就是他能够采集图像，但是我觉得一个是他采集图像有没有用？比如说现在我采集图像有什么用？对，那我录下音就行了，对吧？就好像不需要头像的这一层界面的信息。另外的话，大部分人，今天应该有一半人是不戴眼镜的，我是这么理解的。但是在这个屋子里，这个统计好像不成立。

汤欣钰 08:58
对，我就想说，这一半多的人难道会为了要用 AI 就去戴上眼镜嘛？我总感觉好像哪里不太对劲。你懂我意思吗？嗯嗯，何况他做得太小了，能做到七龙珠那种，就戴个那么小那么酷的。对，我觉得是五年之内发生不了，能量密度不可能达到那么高，对吧？啊？如果真的按那个程度的话，我觉得那应该也是电动车相互明白意思。这个摩尔密度档位的时候，我觉得今天还是眼镜的问题，是不是刚需。但电动车也许就 100% 替换燃油车了，对吧？对，不要瞎说，对吧？我觉得眼镜总感觉好像，以前有一些眼镜，它能够帮我们刷掉一些东西。但是不要你帮我采集一些东西，但是这些东西能采集好，但不是必须的。让他能持续采集，我觉得都是问题，待会再说。

汤欣钰 09:56
所以我就觉得，上周的话，周四、周五我当然有交流，我最近的感觉就是语音这个事情确实可能是有点低估了。对，我觉得纯语音这里面信息量其实很大啊。先说问题，你待会再说到这。对，待会我可能会讲一下今天我对语音这边的一些思考，还有吗？没有。行。对，上周那个缺讲那个机会以后，我说重新思考一下语音这个地方。嗯，我觉得，其实我还是准备一个假设，就说围绕着一个人的记忆里边，或者围绕一个人的数据，对吧？个人的 data，对吧？啊？你也可以直接叫个人的 context，对吧？对，对。就这些东西加上我们之前说的，加一些智能，对吧？啊？自己加个大模型，对吧？他可能就能够解决一些问题。
汤欣钰 11:09
对，然后我觉得今天，嗯，各种文章看，包括一些我觉得客户软件没有好的原因，还是主要缺在这个地方，这个程度太低了。假如说我们最终这个也许是终态啊，这个地方可能连着个人的数据可能都是 100%。但是今天我觉得可能也许连 10% 都没有达到，我没拿到。比如说我们今天说的话，我们看的东西基本上都没有数据化，对吧？他可能不但造成眼镜挂着项链，那其实是提升这个东西啊。

汤欣钰 11:43
嗯，然后另外的话，还考虑多模态，是吧？就是上次那个“陪伴”那篇文章就讲得很好。第一就是这些数据，在 APP 厂商和手机厂商里面，他们对这些人拥有数据。今天你想创业，其实你也没这些数据，是吧？第二就它好像量还不够多，好像量也不够。所以首先第一个问题是已经垄断了，第二今天垄断阶段量也不够，量还是少的，比较难受的。

汤欣钰 12:17
第三，它的这个丰富度不好，多模态它这个质也不好。比如说连语音大部分都没有度。现在 APP、手机也没拿多少用户数据，对吧？然后更比如说你们看到的这种多维度的数据，更是更少了。那主要是有一些虚拟世界里面的数据相对多一些。明白。但今天整体都是不好，或者不够好，导致最后这个地方逐渐成了瓶颈啊。

汤欣钰 12:51
没错，那我们可以直播间有什么呢？哦，我自己觉得今天我们，比如做这种像 QBOX 这种公司，其实有他这个东西，基本上有可能你的虚拟世界里面的，特别是网页端的，可能很多基本上他都能拿到了。当然 APP 内的这样比较难拿到。

汤欣钰 13:14
但是这种在 APP 内，比如今天你小红书、搜房间东西，然后微信里面的文章基本上也能拿到。网页上直接也能拿到，很方便了。他已经能拿到大部分信息，通过这个渠道能回来。比如现在我希望每天看虚拟的文章，基本上信息都没说，在这个地方国家可能更自动。

汤欣钰 13:35
对，还有一个的话，今天这些语音类的，或者说既然靠听说这种情况，最大的问题就是什么？它可能是文字，可能这些文字主要是一些文字，对吧？你有的信息是听不见的。比如说以个人感官，很多是你看见了别人说的话，对吧？然后你敲打字这些东西就有了。然后今天发现什么？微信里面，比如说微信咱俩的对话其实都可以转发给 QBOX，他们把这些信息也能存。所以这种看见的文字的，基本上我觉得差不太多。

汤欣钰 14:18
嗯，听说类，对吧？然后还有一个就是针对视觉类的，对吧？图像类的应该更强调这种图像类的。对吧？看你的眼睛、耳朵，对吧？这些。可能再高级的话，可以嗅觉的咱先不说，那些可能更难。所以我觉得今天这个东西是很好形态。我觉得它今天已经解决了我很多的采集问题。但问题是，这个我看不过来，跟采的好像都放在那堆基建里。今天采的地方还不够吗？采的地方我们不是采的地方，我们远远走不动。对，我们今天说的大部分都没有录下来，对吧？然后数据量、存储量其实都远远大于这个东西，明白吗？所以我觉得这个地方要是落，就跟你这边再说，我们再来分一下。再分一下静态，随便这样分，对吧？那就是拍照，对吧？还有动态，对吧？那就是 video。

汤欣钰 15:44
对，其实我自己觉得今天不太用眼镜的时候，极少的人需要用眼镜。其实大部分人用手机拍今天也是挺方便。对，就我觉得今天眼镜除了第一视角以外那个独特性，当然大家也有。所以我最近在体会，我感觉这个东西，包括他们在主管群里就说，大家觉得一个故事特别好。就是一个盲人看不见前面东西的时候，你问小爱同学“前面是什么？”，大家觉得这个故事很感人。除了这个以外，好像其他同学都有点，“对吧？你说你，我自己戴个眼镜呢，对吧？我问小爱同学前面是什么？”，觉得这个确实没什么。

但是那个米 Case，我还感觉，嗯，假设我说这个米 Case，对，就是假设，它能接受到我每吃一口，每 11 口，它的质量。如果能够继续吸引，精确地记下，其他就无所谓。你说采集的形式不一定是眼镜嘛。对，我觉得是这样子，就是它确实有好处。

汤欣钰 16:49
别人就说很多时候你是被占用的时候，但是我觉得这个东西其实确实多了那么一步。但我觉得这个场景是因为我们自己也在用，感觉也就那么回事。嗯，对，就是你是不是每一份都拍一下？何况今天的话，有些算法识别还不是那么准的时候，那确实。嗯，对，它但是能打中一些人，因为这就是一个产品。这个场景切得比较好。

汤欣钰 17:18
但是今天它到底，反过来再抽一个场景，还有没有其他场景？如果光这个场景，其实这个东西有点……对吧？我也觉得，能给我戴个眼镜，是吧？那我每天拍几次，对吧？问题不太大，但还是不够。甚至，对吧？极端情况下，今天很多都是吃的。比如说我吃食堂，比如你今天自己做饭的时间有多少？很多时候吃食堂、吃外卖，其实这东西今天真的特别一样。今天必须有份数据，对吧？可以算得更清楚。因为你最终想拿到卡路里数据，其实并不是为了拍照本身的手段而已，对不对？

假如今天我们之前就在想，其实最理想的其实是——

汤欣钰 17:57
是啊，不是为了让它 AI 而 AI。其实真的是，食堂的人就那么几道菜，你运营一下。甚至让大家更高一点去算出那道菜到底是多少卡路里，这东西可能比今天 AI 智能强太多了。对吧？因为咱们吃的都是一样的菜，那个份量都是一样的。或者让食堂那边每月贡献这份数据，其实是很准的。明白意思吗？昨天就是，这个东西不存在唯一性，但是 AI 其实有点鸡肋，包括大小可能哪些都算不清楚。

汤欣钰 18:33
好，所以我觉得这个地方，就是看，包括网上的，其实很多都是给 vlog 主拍的东西，国家旅游，但这个场景比较低频。但是那视频博主的视频质量要求也挺大的。对，但是他就给一个独特的，对吧？10 岁，嗯，对，给个独特视角，但这个绝对也不是高频。好吧？所以我觉得这个地方今天有点鸡肋，或者优先级不高。

汤欣钰 19:03
反过来说，今天你们每天，其实不知道大家每天平时拍多少张照片？一周下来，对吧？你还是，你有这个采集了以后，你怎么去消化这本书里面的？对吧？你拍完以后，你自己就存着开心，其实过两天你可能就没那个兴趣了，因为你后面没有消费。对，反过来，你首先照片，你能把它发挥一些价值，明白吗？其实今天已经差了，差一个“再摊几道菜”。我觉得，虽然我做过一个东西，但是我们做的就是为了近距离去体验，这个东西给我的反馈到底什么样子。最近我有点感觉，比如说当初我们觉得这个东西能不能帮我采集？我看到微信，但其实这东西也可以比采拍更方便。

就是采集文字、文章，甚至当时我也许都不想读微信了，对吧？帮我去读书。对吧？我现在也不一定需要眼镜，明白意思吗？那更别说支付宝那个“看一眼支付”这个事。7 月份做这些，就是为了炫技。其实真实有多少人会这么用嘛？对，然后最近你跟它碰一碰不更方便嘛？我碰一下，对吧？要分数的话，体验我虽然还没有完全用起来，但是我老婆老用。对吧？那碰一下不更好？你还得“小爱同学，扫码支付，确认支付”。我靠，有好几个步骤呢。能理解吧？好几步太多了。对，所以从业务角度来看，它没有感觉增加体验，反而像增加任务量。对，所以肯定是只有在非常非常小的这种罕见场景下……

汤欣钰 20:42
再说一说，好像听起来有用，OK，我就拿了一堆东西，但这个东西感觉额外增加了限定图，这个东西可以用。嗯，好，还有真的很多感受很明显的是，上周不是我们两个找你那个做，你看边做边想嘛？嗯，那你建议我们想清楚再做嘛。我感觉眼镜明显就是一个没有想特别清楚，然后就上了一下。

汤欣钰 21:05
很明显就是，包括我们那边的产品，包括我们的研发都觉得可能也不是特别好，但是还是得往重做。我觉得试错其实是值得的，但是试错完以后，我们就要去思考下一步，再努力发力。我觉得对公司来说其实还好，但是我觉得就是说，因为我之前也是，我也觉得，对吧？因为试完以后，比如说他会有一种体感啊。

汤欣钰 21:32
嗯，那这个有时候我觉得还是要探索的。但是我并不是否定他做这个东西，但是做完以后我们就得思考你下一代要不要做？下一代怎么做，对吧？你下一代市场份额是乘以 10 的，还是原来的？这个就是第一个。怎么做其实都行，对，行吗？大概就是这几类啊。所以我之前觉得这个地方是个重大机会，然后唯一的踩坑问题，我就直接说一个。那包括这边，比如今天拍视频，拍这个视频其实运动是一个专用场景，对吧？那包括我们说的，我自己拍的最多的，比如最近老拍的网球，我一周可以拍。这个周末的时候，最后那天打了几个小时，对吧？然后就拍了几个小时。

汤欣钰 22:17
这个眼镜是搞不定这件事的，但是我用手机就可以解决，也可以解决 video。那个专业的 video 最好是跟大疆，对，是吧？这些东西可能解决的。所以我觉得这个地方可能运动场景、旅游这种特定场景的照片相对来说还是高频的。刚刚那个眼镜，在这一方面可能还是有一些更疯狂的人群时尚。但之前的话，我觉得基本上别人已经解决了。在他基础上能不能做自动化，包括后面一些执行，而不要说今天我去每一步踩。

汤欣钰 22:57
对，然后今天这个地方你想的就是说，就还是我戴这个东西。上周那个给我启发，进一步地想，我就在想，这东西又呈现思考。我觉得这个东西想象力还是比实际大。他说，我是这么想的：还是首先你雇人就负责一个 AI，就雇人。对吧？那我在这雇什么？哼，我形容一下，虽然你雇了一个助手，但这个助手有点缺陷——你雇了个瞎子助手，但这个人的情商、智商都很高，只是个瞎子。然后你想一想，假如你今天这个瞎子助手可能比较小，它能随身就在你的肩膀上，对吧？小到别人看不见，是吧？你想想它能给你干什么？而且是一天 24 小时。

汤欣钰 23:59
我讲一下，比如这个东西它就是 24 小时，其实我这是仔细在想，我是不是下的步骤。就比如在地库里面，我听到很多声音，因为声音频道我是忽略的。但是我觉得如果我现在就是真库的这个项目，它其实知道我在地库，它可能知道我上车的，它可能知道我现在在开车的，甚至我在食堂吃饭，它可能都知道我现在就在食堂吃饭。他不用看见，能理解吗？

汤欣钰 24:36
嗯，但是我觉得它未必那么准确。比如说现在这个场景跟你在车里，如果不说话，大家都很安静的话，可能区别不是很大。他就是没感受到你身边有声音，对，没有声音就没有了，对吧？但比如在车上，首先我们在开车的声音其实会有一些，对吧？然后在车上可能听学习的内容。比如我觉得最有意思是什么呢？就是比如我在车上，那我就会打开一个“小宇宙”，比如说自己爱听播客，对吧？它会听到我现在听的是什么内容。进一步，它可能难点就是这些算法。

汤欣钰 25:16
你到底是在参加会议，是吧？还是在听学习的内容，是吧？但实际上这里面又有个信息，就是说我的手机上大概率是从手机发出来的，或者我有开启“小宇宙”APP 的行为。其实它结合这个的时候会非常精准。就相当于是虚拟世界里边还有手机。对吧？它会在这里看到有一个世界，是吧？打开了“小宇宙”APP，同样的时间，它还能听到开始有一段……嗯，就是它要结合别的信息，它不能完全只靠声音。如果再结合这句话，其实就是非常强大。这时候对上岗要求就变低了。对吧？你看，它有另一感知，但是光听，其实也比想象中要强大。

汤欣钰 26:06
但是如果在认知层面，可能对算法要求就高一点。但是我们给它另外一个维度信息以后，包括地理位置的移动信息，这些都有。嗯，对吧？所以现在有人告诉它，这个时间主人打开了什么 APP，这个时间主人到了哪里，对吧？但它就靠听，其实也能还原出一个非常好的“记忆逆天”。

汤欣钰 26:32
几点出门了？几点学习了？在车上干嘛？听了，首先学习了，还是说只是吃饭的声音？是吧？吃饭声音忽略了，没声音，就是默默开车，就可能是吧？然后几点进了地库？甚至我们按电梯。但是我觉得还有一点，就是说假如是一个瞎子在身边，他会有个能力，他可以问你。如果他现在听不清楚这是什么，他不知道哪块是什么，他听出来很奇怪的声音，频率很高，比如“嘟”的一声，“duang”的一声。他可不可以反过来问你：“主人，这是什么声音啊？”比如现在开会了，那就是“主人你今天在跟谁开会？”这个是在跟谁开会，对吧？比如告诉它一次，它可能就知道了。我告诉它这是电梯的声音，是我家电梯的声音，和小米办公楼电梯的声音，可能“嘟”的声音都不一样。我们现在在体会叮咚叮咚那个声音，对吧？包括说到第几层了，对吧？这个东西有人可以反馈给它。它问的话，人就有标注。对吧？其实生活中高频的几个声音，在你的不同环境里可能是高频的，但一旦学会以后，它慢慢就知道“这是又到哪了”。

汤欣钰 28:00
明白，就是场景确实想象力很多。关键是这东西真的可以淡机三天，你什么都不用管。嗯，对吧？早期没有啥用，但是你也不用理它。你不用又开又关。我觉得这东西对人的成本要求很高。但反过来，这东西一直在录音，24 小时，对吧？这样它就切出来了，它就在分析，尝试分析这段时间段。进一步不知道的话，你可以用别的 APP，或者信息告诉它。其实这样下来很快，我猜我的畅想就是，它会不会很快地——其实就是“嗨，你好”。然后你也不用单拿设备。假如说你还能代替 3 天，对吧？对，代替三天。每天你把数据同步，它就开始整理。

汤欣钰 28:59
一天这个东西今天也不做实时的，我觉得实时今天非常难。对吧？对，它每天你晚上放在那儿，它给你第二天输出前一天你在干什么。然后这些可以修正，可以说这块不是吧。我觉得人的反馈很重要，人可以交互。就像这个瞎子助手，你跟他交互。其实市面上的应用，还是以文字为主。就算录音，它可能也是先转文字，然后再处理。如果是这种形式，它并不能识别你的其他类型声音。对，所以要我说，声音很重要。我觉得采集性，还有长时间采集性，今天是比较成立的。中期就算特别好，它也不成立，对吧？所以我觉得这个地方今天采集成本没什么问题，没什么障碍，所以就可能得压这个东西，保持这个项。

汤欣钰 30:11
剩下大家做创新，比如说今天你就是光弄文字嘛？这东西可能就有点……是吧？但是你包括刚刚说的，因为本质上是，我觉得什么呢？在没有数据逻辑那肯定要再打一些疑问的。嗯，是，对吧？这是在开会，然后出来才 summary，是吧？但是有些疑问的，比如我几点出门了，对吧？如果你能到这个程度，其实就最牛逼了。对，明白吧？现在不管怎么做，只要能做到这个程度，其实就牛逼了。只是还是个声音的信息嘛？那就开始。

汤欣钰 30:43
它就能达到一个助力的效果，因为它快速理解了你今天在干什么。所以我觉得今天不是一个简单的。我觉得有点像图像分割。今天我在思考到底是什么问题？有点像一种分割。好，可能我们先把它分一些段子，再把音频切开，对吧？然后音频再去理解，一段一段在干什么，或者提取出来关键事件是什么。

汤欣钰 31:16
就是感觉比较难。假设我就想说我是一个人，我听你这个录音，我能帮你分割出你一天的段吗？各位，我觉得也比较难，我也不是。但你还有很多数据的，比如日历数据，对吧？所以还有其他维度可以教它，帮你验证。比如今天我几点开会，那我在开会的时候，日程上得写那块，对吧？当然肯定会有冲突，比如说日程上写了但没开，那你再去分析内容是不是匹配一句话，这样就容易对上。包括这段声音其实跟另外一个会的声音大概率是不一样的，对吧？只要能清楚我的，就还是我自己在想，我是那个瞎子的时候。

汤欣钰 32:07
对，我觉得起码要处理的是一段一段。还是那句话：今天人能干的事，AI 也应该能干。我觉得更简单的解决方式难道不是结合照片图像吗？就是它比如说不用一直录，它可以每隔一段时间，或者觉得你有变化的时候帮你拍一张。如果发现环境不同了，它就能确定你在做别的事情。

汤欣钰 32:35
对，所以在这块，你说贴眼镜是吧？甚至我们可以拥有敲击按钮什么的，让员工帮他分类片段。比如说我这个，但管理我还是觉得容易忘。比如开会忘了敲了，对吧？就是拍照可以让它无感地执行。所以如果这样的话，拍照相当于在片段上再打一层标签。比如你看这块，这是这个场景，对吧？再辅以照片，就是这个时间对应的画面。你分析一下。因为一般来说图像信息量大于声音，可以的。所以我觉得图像可以做辅助，但很难作为主线。明白吗？这在第一步的时候拍一眼没问题，所以还是多传感器融合。一天都能，甚至能录三天，加上定位和步数信息，就可以知道具体情况。所以我觉得还是会有很多看板可以辅助。但今天的话，录音是可以做到不间断的。

汤欣钰 33:44
嗯，也许两到三天，我觉得这是之前很少的一个点。其他东西都可以增强它，但主还是这个东西。当然还有主就是浏览器插件。在 PC 上看不见，对吧？也很难听见，它是无声的，对吧？持续度也不现实。但很多浏览器插件，大部分行为都能被插件捕获。这样的话，记忆就很强了。

汤欣钰 34:16
剩下的时候我们要开始思考：这东西有这么多强力数据，把我们里面的几个问题全解决了，或者解决到绝对优势。以多维标的标准，那可能都是契合的。这时候我可能会有突破。另一种，别人之间就一个眼镜，因为它早就压到 60%，都是片段性。嗯，还有点。比如今天出门问问讲了个故事，说让它帮你听家长会。你自己去参加复盘会，线下的。

汤欣钰 35:00
对，他有这么一个故事，说是一个妈妈，可能三年级小孩的家长会。我觉得这个故事有个问题，就是今天它故事里还是一个人在干这个事，另外一个交给 take note。就是说定一个帮你联系的第二个人。对吧？但小米可能想的是更高级的，也许线下会议都可以用，甚至多个行业的东西。最终硬件不限的。我同时有手环，同时有这个东西，同时手机上还可以开录音。上次我给大家演示过能录音吧？今天开飞书，连小米的录音机都没录。

汤欣钰 35:45
我给你们看得到。所以我觉得通过更多传感器，甚至手机，把它压到 100%，保证所有语音都能间接汇总到这里。甚至现在多个设备，你布三个，都在挑战系统里。之前我觉得手环很难听到，比如耳机估计很难，但今天手机上会存下来，甚至能合到一起。算是融合。

汤欣钰 36:20
对，嗯，所以这样我们可能结合小米。今天小米在微信、飞书上都能采集声音。好，这个东西之前大家都不知道。对，这其实现在是有这个功能。飞书通，上次网络上试过，你应该看过，对吧？是谁也看过，对吧？所以打电话实时录音效果就知道了。嗯，就是所有东西。对，现在有个开应用内录音的小姐姐打，所以其实可以。新月没看过，是吧？就是这块。别说，你们过来看，有会议，有些信息就自动录。这就是响手机。你说的什么？你再说一遍，你是谁？嗯，换回去。哎，就先，这不是 chat，它是录音机，它能实时识别。我在想能不能把人识别改成，说话申请的时候它能识别我是说话人。嗯，好像分不开。嗯，小爱同学，这就是小米录音机现在带的功能。但这个功能现在小米人都不知道，生不生气？哈哈哈。但这个功能埋得很深，要进录音机设置，再找应用内录音，再找授权，再一个个打开。

汤欣钰 38:24
对了，起码我问了一圈没人知道，包括旭哥他们都不知道，只有手机产品的人知道这个功能。我感觉没准备让人能用。哈哈哈。我就好奇，为什么要做这个东西？有点像，一开飞书会议，豆包就跳出来说要不要帮你入职。对，所以其实在手机上，豆包的功能小米已经掌握了。

汤欣钰 38:50
所以在这个地方我觉得音频就是一种语音，这个东西我们应该能拿到 80%–100%。嗯，然后再做好隐私保护，是吧？然后用一个助手去分析事件，而不要直接把音放出来。再做一些脱敏保护。比如说，上厕所这种无意义的可以过滤掉。哈哈。

汤欣钰 39:19
嗯，对吧？所以说，这个交叉的东西，可以让我们今天的语音达到非常高的利用率。最简单的是生成文字，但是生成文字要能分成一段段有意义的东西。这可能是一个关键基础。所以今天换个角度，我们在做什么？就是在获取虚拟世界的记忆。这方面小米不擅长拿微信数据。阅读类擅长，但通过这个渠道我们能拿到。后面也要加强。运动时，我们可以通过照片头切入。这样文字、音频、图像就全了。再往后就是更深层的。

汤欣钰 40:19
我们 GMV 看得还有传感器、医疗那种更专业的。你再说这句话，起码大部分人都有。然后这块可能解决消费数据的问题，学习新知识的问题，解决日常处理问题。大家都很痛，比如 VC 在想的卡点是什么？是算法问题，还是设备增强？他判断很需要设备增强，比如全麦那种全方位的麦克风，把它们增强。

汤欣钰 41:00
嗯，是的，就是有一些可能录下来质量也不是很高，确实感觉……嗯，对。但这时候可能远端就没有听清，对吧？他可能就听不太清楚。那看可不可以在硬件上分享？对，他是愿意做一个运营倾向。有机会，但不太可能做到 800 人之间，非常低。那这玩意今天才 200 块钱，其实我听下来录得还不错。回头我可以，比如截一段，把今天那会儿放一放。可以听的。飞书会议录了，很多人都听不清飞书，但它好像能识别出那些。对，它可能这种 Mac 会挡住的原因我不知道，有时候反而在那边，对吧？反而能听到。说不定你放一个开放式的反而更清楚。因为这个会议室回声太重，声音容易被反射。所以讲起来回音很重，录下就是嗡嗡嗡的。我回头把这个先……

汤欣钰 42:11
嗯，大家可以看一下。我那边查了一下，通过硬件能做到跟人耳差不多，我感觉有些懂我意思吧。嗯，我觉得其实，对，再结合上次说的隐私保护情况下，录音以后……反正我觉得用户是有需求的。录音这事确实很可怕，很专业，但普通话下一步走。

汤欣钰 42:43
嗯，然后还有一点，就刚那天，其实你包括看手机。原来我们数据特别痛苦的是怎么拿 APP 内的数据。对吧？但实际上那天我想，诶，我要看 B 站，然后很多时候都有音频信息。同时我就采音了。之前我特别想去采视频的，但今天觉得采音频好像更容易一些，而且信息量也不少。比如刷抖音，对吧？你大概率能知道同事在刷，起码能知道刷的哪类。我靠，所以我在想，如果没有视频，其实信息量不一定少啊。你知道在看 B 站，看什么视频，这东西原来小米很难拿到。

汤欣钰 43:32
原来我老想拿个视频，但后来想到，这东西其实不一定要视频。当时我特别看重眼镜，是因为它能帮我们采集到很多小米采不到的数据。但后来发现它采集量太少了，突然发现信息量不一定差多少，里面都是模拟采集。好吧，这个大家可以再想一下。嗯，所以这样，我们可能最终拼的就是这个东西。小米这设备为了感知更强，快速压过临界值，再结合小米在虚拟端、设备端、应用端的东西，就很强。这就是我们在做的应用——让你每天都觉得网络离不开下一个助手。最后可能就是培训的手段，让它随时随地采到，最终全部汇到一起。

汤欣钰 44:43
非常多，大家看什么问题？

汤欣钰 44:52
其实提到它，我在想，当时卖火的原因是因为苹果当时并没有开启公共权限，所以它可能用外挂形式做了。我感觉这就是发展起来的关键节点。嗯，对，推动的。我看了一下，感觉做得很杂，就是今天想的功能太多。但是我觉得，我今天真的是希望无感。我觉得不要求那么实时，我们不要求那么实时。我觉得实时很难。反过来，如果我每一小时都不用动，最好不用太干涉，但最后一天下来让我有会议系统。哇，能把每个会分得很清楚，对吧？甚至加上会议的线索能力，知道哪些会的线索，准确度已经很强了。好吗？嗯，最好里面还不要太多人参与，最多告诉我，他问我“这是谁的声音”，我都能远超。那可以，这是声纹嘛。

汤欣钰 46:08
就是这些数据采完之后，我们要做什么应用？听起来还是像一个笔记一样的东西，是吗？我觉得今天，你看你发的东西，我觉得还是一个大框架没问题。就是先要做到，今天 AI 能不能把你记清楚。实现个人全面记忆，对吧？哪怕 60%，刚才说的，几点在干什么？几点到公司？几点开会？会议讨论什么？我觉得这个本身就已经很强了。对吧？或者基于今天这个基础，这个东西，完全可以扎到很强的记忆体系，推动起来。嗯，我觉得这就是最大的缺口。然后你想，在这个基础上，AI 到底能不能帮我干点事？我觉得有了这个基础，后面问题不大。

汤欣钰 47:09
哇，有太多痛点需求了。比如记忆先记完，对吧？文档能记一下，再调用离线的东西，执行一些任务，再包括 deep research 去分析探索一些东西。明白？所以我觉得这是整个后面的基础。没有这个，你就没法理解。否则你下次也不能指挥别人，“你在干什么？”、“你在干什么？”。这事就转不起来。所以我今天觉得模型是指数级上升的，但个人数据还是态度在提升的时候的瓶颈。

汤欣钰 47:54
反正这是我的一个假设，一个大假设。核心假设就是最多我们把这个东西带上去。别人都在讲记忆，剩下的是我怎么比别人更快，把数据汇聚到高水位。别人做到 70%，我能做到 80%，甚至 90%。还很便宜。最终拦截的设备都能复用起来。我觉得这是我们现在的大价值。但这些东西都像刚刚说的，被垄断。对吧？垄断在一边，我们也监控不全。但能不能把这个垄断做得更实一点？你看，我就是垄断。对吧？所有人后面再建应用、分发，基于这个隐私保护去做。

汤欣钰 48:38
一开发，你帮我解决了对主人的了解，剩下还能帮我什么？对吧？那咱一起来。好，配个另外一个。所以整个框架不太会变。包括今天你发的那个 if，对吧？嗯，我觉得就是那种框架。现在大家都在切，对吧？在认证点上干啥？但我有全部信息以后，其实可以分发很多。

汤欣钰 49:07
嗯嗯，还有人能帮我干点啥？好吧。明白。我先开始，就做个一天的记忆度，对吧？做个预记忆。我觉得这个已经很震撼了。做到这个，后面所有人都知道干啥。但今天就是干不出来。好，那就是我的观点和假设。然后就是多设备文本。诶，我再画一画，大家也想想，包括有什么问题，还是放心开。逻辑哪里不顺？可行性、必要性，有没有漏洞？可以筛选出来，更早发现问题。好吧？想想怎么点。也是这一进来就在想，包括专业设备。我是处于一个“我来用它提升生产力”，或者“我来用它做个人提升”。

汤欣钰 50:20
嗯，做个人提升这方面，其实本身跟抖音那种放松逻辑差别大。那种使用意愿可能比生产力工具更强。虽然生产力更高，但娱乐性产品会不会更……比如做娱乐产品，我会判断这不是小米的基因。

汤欣钰 50:45
对，然后这是第一个判断。比如搞 AI 游戏、娱乐，这都不是小米的。明白吗？其实可能碰到的是一种机会。对，起码不是现在。我觉得现在还是先把生产力底线解决，做一个更好的生产力工具。手机本来也是生产力工具，再变成娱乐的。那先把 24 小时里释放出两小时，不用开会了，少做总结。包括去年说的，记不过来。8 月份会开了 8 个，面试完都记不住。那就先把这个地方打透。包括我说的，我对行业的判断是，可能早期先节约生产力，save time，节约时间，释放时间。等释放完以后，才会有增量的新的东西，可能是玩的。比如运动群体，每天打球，也没别的事，就是玩。能玩出花来。但虚拟人玩的，我觉得今天可能还是不能抢机会。行业也许还可以，但现在大家没时间玩。

汤欣钰 52:07
对，所以我觉得整个 AI 可能先是释放生产力，执行生产力，释放时间。没准就能释放出更多玩的时间，那大家去创造。原来可能没有精力创造。我觉得先把第一个事情做好，第二个事情就不是小米的机会了。等把第一个事情做好以后，再看有没有机会去做第二个。因为你整个对人这么了解的时候，没有人可以见一下玩得多好的游戏。或者我在想，在这种工具基础上能不能加一些娱乐？是可以的。将来因为你懂他以后，对吧？嗯，你现在这个助理也会很了解主人。

汤欣钰 52:50
你后面就看你往哪方面引。你是往成瘾引，还是往创造引？对，这就是系统设计要考虑的。我自己希望是往创造方面引。大家既然能工作流，是吧？嗯，真能释放创造力。就像 Sophia 那个人讲的，他采访时说还想看到人被解放出来后的创造力是什么样子。人家就不用再为每天枯燥无聊的工作苦恼，对吧？每天处理表格、处理文档。释放出来以后，人就有很多时间。总有些人能创造。可能 1 万个人里就有一些。这样就不再是幻想。好，行，还有什么问题呢？今天做的事情都在这个框架里。包括群里的运动，其实我们也在切视频，但不太想切眼镜，因为别人做过。我们就切运动专业的。结果今天坦白讲，用手机就可以了。可以。那现在先用已有的去做一些，也是 OK 的。

汤欣钰 54:12
对，然后我们就学习别人。这个地方，我们先学习一遍。因为我突然感觉这个机会面比较大。小米这些设备都能融合，这地方看出来以后能快速压过去。嗯，明白，所以这是主线。其它都是我们借助别人的技能，先把别人学会的汇总到这块。

汤欣钰 54:45
好，我后面那个线下课题，嗯，大家来消化一下。好，好，海南的照片。对，这样的话，我们就有几条线，好像就会有一个整体。嗯，对。是的，你在想音频和视频的切割识别，本质上也是一样的，只是介质不一样。对吧？我能视为音频的一个事件，你去识别。视频其实还不太一样。音频更多是转文字。视频主要还是关注，其实也是一种转文字。比如“他打了个正手”，就像你跟瞎子助手一样。对吧？“他打了个正手，他球速多少多少”。这些信息是可以用文字描述的。天级别做了一版实时，还是可以。但实时难度几何上升。

汤欣钰 55:39
对，所以实时先不要着急。我们先做离线的。离线之间就能解决很多问题。就不用再整理会议了。一会儿要一块记“这是我的会，那块是欣钰的”，到时再想办法把两个相同的合在一起。嗯，他们家最近开始出广告，我观察评论区，大多数人确认的一点就是“为什么我要买一次”。但也有很多人说就是文章退款解决。你帮我拿一下这个东西，等一下开始。对，好。